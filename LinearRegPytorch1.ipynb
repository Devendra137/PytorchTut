{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbPCqgCVlLw+bgLcAGGjdR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devendra137/PytorchTut/blob/main/LinearRegPytorch1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "2ARInYEKHR1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qBfrgY3HBRF"
      },
      "outputs": [],
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "JCIwcEMrHLV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "FVc74qYCHO_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHkVeoWfHZCX",
        "outputId": "0d91f4ff-b403-45fc-de35-2524ebedc53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(2,3,requires_grad=True)"
      ],
      "metadata": {
        "id": "c06Dx2-2HgS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.randn(2,requires_grad=True)"
      ],
      "metadata": {
        "id": "xO3RfIK8fmtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uRGBqlVf3wF",
        "outputId": "c33ac5a5-46c3-4af4-9938-0c2b2168a808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5814, -0.9496, -0.6782],\n",
            "        [ 2.1112,  0.0158,  1.0257]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCsxSMrJh4so",
        "outputId": "2c4cc363-b603-4c94-c3c6-3737ebf1ffaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4280, -0.3113], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "    return x @ w.t() + b"
      ],
      "metadata": {
        "id": "xKq---HCh5nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalmod = model(inputs)"
      ],
      "metadata": {
        "id": "x_UAkgi-iOYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(finalmod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lko4R6Ein2zT",
        "outputId": "6f0f13d5-6733-4bb2-8b6a-05765a677257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-207.7943,  198.9709],\n",
            "        [-270.4415,  258.8443],\n",
            "        [-303.7269,  244.9746],\n",
            "        [-226.7953,  253.6605],\n",
            "        [-247.3170,  218.6793]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(t1,t2):\n",
        "    diff = t1-t2;\n",
        "    return torch.sum(diff*diff)/diff.numel()"
      ],
      "metadata": {
        "id": "GSNoSHUFoUs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mseloss = mse(targets,finalmod)\n",
        "print(mseloss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfdCLZaLoh3F",
        "outputId": "39ed6997-e109-4ea5-afa3-28f3f805590f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(66738.2031, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mseloss.backward()"
      ],
      "metadata": {
        "id": "nByAKY4pomes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsU8nwKMph-1",
        "outputId": "599f6d92-9550-43c9-caf4-8c07d1a211f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5814, -0.9496, -0.6782],\n",
            "        [ 2.1112,  0.0158,  1.0257]], requires_grad=True)\n",
            "tensor([[-27512.8789, -29915.0195, -18416.2363],\n",
            "        [ 12499.5498,  11284.3125,   7427.2607]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "metadata": {
        "id": "VU7Tp2OKplfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9g4zKHQrCSo",
        "outputId": "c4365b04-6fa3-43b6-db23-97d2bd749972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.1699,  2.0419,  1.1634],\n",
            "        [ 0.8612, -1.1126,  0.2830]], requires_grad=True)\n",
            "tensor([ 0.4608, -0.3256], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finalmod = model(inputs)"
      ],
      "metadata": {
        "id": "rJtGiETkuio1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mseloss = mse(targets,finalmod)\n",
        "print(mseloss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJiEkHfdutt-",
        "outputId": "bea58676-49d3-4773-ade6-02f493347252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(42193.3320, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(100):\n",
        "    finalmod = model(inputs)\n",
        "    mseloss = mse(targets,finalmod)\n",
        "    print(\"For {} iteration loss is {}\".format(i,mseloss))\n",
        "    print(mseloss)\n",
        "    mseloss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4MEVHh3rEys",
        "outputId": "5a20e5c1-bfd5-49bf-f494-760135fd7b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 0 iteration loss is 435.68719482421875\n",
            "tensor(435.6872, grad_fn=<DivBackward0>)\n",
            "For 1 iteration loss is 430.2472229003906\n",
            "tensor(430.2472, grad_fn=<DivBackward0>)\n",
            "For 2 iteration loss is 424.87579345703125\n",
            "tensor(424.8758, grad_fn=<DivBackward0>)\n",
            "For 3 iteration loss is 419.57196044921875\n",
            "tensor(419.5720, grad_fn=<DivBackward0>)\n",
            "For 4 iteration loss is 414.3351135253906\n",
            "tensor(414.3351, grad_fn=<DivBackward0>)\n",
            "For 5 iteration loss is 409.16424560546875\n",
            "tensor(409.1642, grad_fn=<DivBackward0>)\n",
            "For 6 iteration loss is 404.0586853027344\n",
            "tensor(404.0587, grad_fn=<DivBackward0>)\n",
            "For 7 iteration loss is 399.0174255371094\n",
            "tensor(399.0174, grad_fn=<DivBackward0>)\n",
            "For 8 iteration loss is 394.0396423339844\n",
            "tensor(394.0396, grad_fn=<DivBackward0>)\n",
            "For 9 iteration loss is 389.12469482421875\n",
            "tensor(389.1247, grad_fn=<DivBackward0>)\n",
            "For 10 iteration loss is 384.271728515625\n",
            "tensor(384.2717, grad_fn=<DivBackward0>)\n",
            "For 11 iteration loss is 379.4798278808594\n",
            "tensor(379.4798, grad_fn=<DivBackward0>)\n",
            "For 12 iteration loss is 374.7484130859375\n",
            "tensor(374.7484, grad_fn=<DivBackward0>)\n",
            "For 13 iteration loss is 370.07659912109375\n",
            "tensor(370.0766, grad_fn=<DivBackward0>)\n",
            "For 14 iteration loss is 365.46380615234375\n",
            "tensor(365.4638, grad_fn=<DivBackward0>)\n",
            "For 15 iteration loss is 360.90911865234375\n",
            "tensor(360.9091, grad_fn=<DivBackward0>)\n",
            "For 16 iteration loss is 356.41180419921875\n",
            "tensor(356.4118, grad_fn=<DivBackward0>)\n",
            "For 17 iteration loss is 351.9710998535156\n",
            "tensor(351.9711, grad_fn=<DivBackward0>)\n",
            "For 18 iteration loss is 347.5865173339844\n",
            "tensor(347.5865, grad_fn=<DivBackward0>)\n",
            "For 19 iteration loss is 343.257080078125\n",
            "tensor(343.2571, grad_fn=<DivBackward0>)\n",
            "For 20 iteration loss is 338.9822692871094\n",
            "tensor(338.9823, grad_fn=<DivBackward0>)\n",
            "For 21 iteration loss is 334.7613830566406\n",
            "tensor(334.7614, grad_fn=<DivBackward0>)\n",
            "For 22 iteration loss is 330.5936279296875\n",
            "tensor(330.5936, grad_fn=<DivBackward0>)\n",
            "For 23 iteration loss is 326.478515625\n",
            "tensor(326.4785, grad_fn=<DivBackward0>)\n",
            "For 24 iteration loss is 322.4150695800781\n",
            "tensor(322.4151, grad_fn=<DivBackward0>)\n",
            "For 25 iteration loss is 318.40301513671875\n",
            "tensor(318.4030, grad_fn=<DivBackward0>)\n",
            "For 26 iteration loss is 314.44146728515625\n",
            "tensor(314.4415, grad_fn=<DivBackward0>)\n",
            "For 27 iteration loss is 310.52978515625\n",
            "tensor(310.5298, grad_fn=<DivBackward0>)\n",
            "For 28 iteration loss is 306.6673889160156\n",
            "tensor(306.6674, grad_fn=<DivBackward0>)\n",
            "For 29 iteration loss is 302.85382080078125\n",
            "tensor(302.8538, grad_fn=<DivBackward0>)\n",
            "For 30 iteration loss is 299.08819580078125\n",
            "tensor(299.0882, grad_fn=<DivBackward0>)\n",
            "For 31 iteration loss is 295.3700866699219\n",
            "tensor(295.3701, grad_fn=<DivBackward0>)\n",
            "For 32 iteration loss is 291.69879150390625\n",
            "tensor(291.6988, grad_fn=<DivBackward0>)\n",
            "For 33 iteration loss is 288.0736999511719\n",
            "tensor(288.0737, grad_fn=<DivBackward0>)\n",
            "For 34 iteration loss is 284.494384765625\n",
            "tensor(284.4944, grad_fn=<DivBackward0>)\n",
            "For 35 iteration loss is 280.9600830078125\n",
            "tensor(280.9601, grad_fn=<DivBackward0>)\n",
            "For 36 iteration loss is 277.47039794921875\n",
            "tensor(277.4704, grad_fn=<DivBackward0>)\n",
            "For 37 iteration loss is 274.02459716796875\n",
            "tensor(274.0246, grad_fn=<DivBackward0>)\n",
            "For 38 iteration loss is 270.622314453125\n",
            "tensor(270.6223, grad_fn=<DivBackward0>)\n",
            "For 39 iteration loss is 267.26287841796875\n",
            "tensor(267.2629, grad_fn=<DivBackward0>)\n",
            "For 40 iteration loss is 263.9457092285156\n",
            "tensor(263.9457, grad_fn=<DivBackward0>)\n",
            "For 41 iteration loss is 260.67041015625\n",
            "tensor(260.6704, grad_fn=<DivBackward0>)\n",
            "For 42 iteration loss is 257.43634033203125\n",
            "tensor(257.4363, grad_fn=<DivBackward0>)\n",
            "For 43 iteration loss is 254.24288940429688\n",
            "tensor(254.2429, grad_fn=<DivBackward0>)\n",
            "For 44 iteration loss is 251.08984375\n",
            "tensor(251.0898, grad_fn=<DivBackward0>)\n",
            "For 45 iteration loss is 247.9763946533203\n",
            "tensor(247.9764, grad_fn=<DivBackward0>)\n",
            "For 46 iteration loss is 244.90225219726562\n",
            "tensor(244.9023, grad_fn=<DivBackward0>)\n",
            "For 47 iteration loss is 241.8667755126953\n",
            "tensor(241.8668, grad_fn=<DivBackward0>)\n",
            "For 48 iteration loss is 238.8696746826172\n",
            "tensor(238.8697, grad_fn=<DivBackward0>)\n",
            "For 49 iteration loss is 235.91012573242188\n",
            "tensor(235.9101, grad_fn=<DivBackward0>)\n",
            "For 50 iteration loss is 232.9879608154297\n",
            "tensor(232.9880, grad_fn=<DivBackward0>)\n",
            "For 51 iteration loss is 230.10256958007812\n",
            "tensor(230.1026, grad_fn=<DivBackward0>)\n",
            "For 52 iteration loss is 227.25350952148438\n",
            "tensor(227.2535, grad_fn=<DivBackward0>)\n",
            "For 53 iteration loss is 224.4404296875\n",
            "tensor(224.4404, grad_fn=<DivBackward0>)\n",
            "For 54 iteration loss is 221.6627197265625\n",
            "tensor(221.6627, grad_fn=<DivBackward0>)\n",
            "For 55 iteration loss is 218.919921875\n",
            "tensor(218.9199, grad_fn=<DivBackward0>)\n",
            "For 56 iteration loss is 216.2117919921875\n",
            "tensor(216.2118, grad_fn=<DivBackward0>)\n",
            "For 57 iteration loss is 213.53768920898438\n",
            "tensor(213.5377, grad_fn=<DivBackward0>)\n",
            "For 58 iteration loss is 210.897216796875\n",
            "tensor(210.8972, grad_fn=<DivBackward0>)\n",
            "For 59 iteration loss is 208.2901153564453\n",
            "tensor(208.2901, grad_fn=<DivBackward0>)\n",
            "For 60 iteration loss is 205.71572875976562\n",
            "tensor(205.7157, grad_fn=<DivBackward0>)\n",
            "For 61 iteration loss is 203.173828125\n",
            "tensor(203.1738, grad_fn=<DivBackward0>)\n",
            "For 62 iteration loss is 200.66390991210938\n",
            "tensor(200.6639, grad_fn=<DivBackward0>)\n",
            "For 63 iteration loss is 198.18560791015625\n",
            "tensor(198.1856, grad_fn=<DivBackward0>)\n",
            "For 64 iteration loss is 195.7384796142578\n",
            "tensor(195.7385, grad_fn=<DivBackward0>)\n",
            "For 65 iteration loss is 193.32217407226562\n",
            "tensor(193.3222, grad_fn=<DivBackward0>)\n",
            "For 66 iteration loss is 190.9363555908203\n",
            "tensor(190.9364, grad_fn=<DivBackward0>)\n",
            "For 67 iteration loss is 188.58045959472656\n",
            "tensor(188.5805, grad_fn=<DivBackward0>)\n",
            "For 68 iteration loss is 186.25430297851562\n",
            "tensor(186.2543, grad_fn=<DivBackward0>)\n",
            "For 69 iteration loss is 183.9573516845703\n",
            "tensor(183.9574, grad_fn=<DivBackward0>)\n",
            "For 70 iteration loss is 181.6894073486328\n",
            "tensor(181.6894, grad_fn=<DivBackward0>)\n",
            "For 71 iteration loss is 179.449951171875\n",
            "tensor(179.4500, grad_fn=<DivBackward0>)\n",
            "For 72 iteration loss is 177.23867797851562\n",
            "tensor(177.2387, grad_fn=<DivBackward0>)\n",
            "For 73 iteration loss is 175.0552978515625\n",
            "tensor(175.0553, grad_fn=<DivBackward0>)\n",
            "For 74 iteration loss is 172.89932250976562\n",
            "tensor(172.8993, grad_fn=<DivBackward0>)\n",
            "For 75 iteration loss is 170.77053833007812\n",
            "tensor(170.7705, grad_fn=<DivBackward0>)\n",
            "For 76 iteration loss is 168.6685028076172\n",
            "tensor(168.6685, grad_fn=<DivBackward0>)\n",
            "For 77 iteration loss is 166.59298706054688\n",
            "tensor(166.5930, grad_fn=<DivBackward0>)\n",
            "For 78 iteration loss is 164.54354858398438\n",
            "tensor(164.5435, grad_fn=<DivBackward0>)\n",
            "For 79 iteration loss is 162.5198974609375\n",
            "tensor(162.5199, grad_fn=<DivBackward0>)\n",
            "For 80 iteration loss is 160.52169799804688\n",
            "tensor(160.5217, grad_fn=<DivBackward0>)\n",
            "For 81 iteration loss is 158.5487060546875\n",
            "tensor(158.5487, grad_fn=<DivBackward0>)\n",
            "For 82 iteration loss is 156.60049438476562\n",
            "tensor(156.6005, grad_fn=<DivBackward0>)\n",
            "For 83 iteration loss is 154.67677307128906\n",
            "tensor(154.6768, grad_fn=<DivBackward0>)\n",
            "For 84 iteration loss is 152.77725219726562\n",
            "tensor(152.7773, grad_fn=<DivBackward0>)\n",
            "For 85 iteration loss is 150.9016876220703\n",
            "tensor(150.9017, grad_fn=<DivBackward0>)\n",
            "For 86 iteration loss is 149.04965209960938\n",
            "tensor(149.0497, grad_fn=<DivBackward0>)\n",
            "For 87 iteration loss is 147.22093200683594\n",
            "tensor(147.2209, grad_fn=<DivBackward0>)\n",
            "For 88 iteration loss is 145.415283203125\n",
            "tensor(145.4153, grad_fn=<DivBackward0>)\n",
            "For 89 iteration loss is 143.6322784423828\n",
            "tensor(143.6323, grad_fn=<DivBackward0>)\n",
            "For 90 iteration loss is 141.87173461914062\n",
            "tensor(141.8717, grad_fn=<DivBackward0>)\n",
            "For 91 iteration loss is 140.13330078125\n",
            "tensor(140.1333, grad_fn=<DivBackward0>)\n",
            "For 92 iteration loss is 138.41671752929688\n",
            "tensor(138.4167, grad_fn=<DivBackward0>)\n",
            "For 93 iteration loss is 136.72177124023438\n",
            "tensor(136.7218, grad_fn=<DivBackward0>)\n",
            "For 94 iteration loss is 135.04811096191406\n",
            "tensor(135.0481, grad_fn=<DivBackward0>)\n",
            "For 95 iteration loss is 133.39553833007812\n",
            "tensor(133.3955, grad_fn=<DivBackward0>)\n",
            "For 96 iteration loss is 131.76370239257812\n",
            "tensor(131.7637, grad_fn=<DivBackward0>)\n",
            "For 97 iteration loss is 130.1524200439453\n",
            "tensor(130.1524, grad_fn=<DivBackward0>)\n",
            "For 98 iteration loss is 128.56143188476562\n",
            "tensor(128.5614, grad_fn=<DivBackward0>)\n",
            "For 99 iteration loss is 126.9903793334961\n",
            "tensor(126.9904, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(50):\n",
        "    finalmod = model(inputs)\n",
        "    mseloss = mse(targets,finalmod)\n",
        "    print(\"For {} iteration loss is {}\".format(i,mseloss))\n",
        "    print(mseloss)\n",
        "    mseloss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZu_iYEBxCbZ",
        "outputId": "a5a47cbb-0a69-4328-dcd5-d7f6724d168e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 0 iteration loss is 125.43912506103516\n",
            "tensor(125.4391, grad_fn=<DivBackward0>)\n",
            "For 1 iteration loss is 123.90733337402344\n",
            "tensor(123.9073, grad_fn=<DivBackward0>)\n",
            "For 2 iteration loss is 122.39482116699219\n",
            "tensor(122.3948, grad_fn=<DivBackward0>)\n",
            "For 3 iteration loss is 120.9013442993164\n",
            "tensor(120.9013, grad_fn=<DivBackward0>)\n",
            "For 4 iteration loss is 119.42658996582031\n",
            "tensor(119.4266, grad_fn=<DivBackward0>)\n",
            "For 5 iteration loss is 117.97037506103516\n",
            "tensor(117.9704, grad_fn=<DivBackward0>)\n",
            "For 6 iteration loss is 116.53250885009766\n",
            "tensor(116.5325, grad_fn=<DivBackward0>)\n",
            "For 7 iteration loss is 115.11271667480469\n",
            "tensor(115.1127, grad_fn=<DivBackward0>)\n",
            "For 8 iteration loss is 113.71075439453125\n",
            "tensor(113.7108, grad_fn=<DivBackward0>)\n",
            "For 9 iteration loss is 112.32637786865234\n",
            "tensor(112.3264, grad_fn=<DivBackward0>)\n",
            "For 10 iteration loss is 110.95948791503906\n",
            "tensor(110.9595, grad_fn=<DivBackward0>)\n",
            "For 11 iteration loss is 109.60966491699219\n",
            "tensor(109.6097, grad_fn=<DivBackward0>)\n",
            "For 12 iteration loss is 108.2768783569336\n",
            "tensor(108.2769, grad_fn=<DivBackward0>)\n",
            "For 13 iteration loss is 106.9607925415039\n",
            "tensor(106.9608, grad_fn=<DivBackward0>)\n",
            "For 14 iteration loss is 105.6612777709961\n",
            "tensor(105.6613, grad_fn=<DivBackward0>)\n",
            "For 15 iteration loss is 104.37806701660156\n",
            "tensor(104.3781, grad_fn=<DivBackward0>)\n",
            "For 16 iteration loss is 103.11091613769531\n",
            "tensor(103.1109, grad_fn=<DivBackward0>)\n",
            "For 17 iteration loss is 101.85978698730469\n",
            "tensor(101.8598, grad_fn=<DivBackward0>)\n",
            "For 18 iteration loss is 100.62432861328125\n",
            "tensor(100.6243, grad_fn=<DivBackward0>)\n",
            "For 19 iteration loss is 99.40441131591797\n",
            "tensor(99.4044, grad_fn=<DivBackward0>)\n",
            "For 20 iteration loss is 98.1998291015625\n",
            "tensor(98.1998, grad_fn=<DivBackward0>)\n",
            "For 21 iteration loss is 97.01030731201172\n",
            "tensor(97.0103, grad_fn=<DivBackward0>)\n",
            "For 22 iteration loss is 95.83575439453125\n",
            "tensor(95.8358, grad_fn=<DivBackward0>)\n",
            "For 23 iteration loss is 94.67598724365234\n",
            "tensor(94.6760, grad_fn=<DivBackward0>)\n",
            "For 24 iteration loss is 93.53074645996094\n",
            "tensor(93.5307, grad_fn=<DivBackward0>)\n",
            "For 25 iteration loss is 92.3998794555664\n",
            "tensor(92.3999, grad_fn=<DivBackward0>)\n",
            "For 26 iteration loss is 91.28324127197266\n",
            "tensor(91.2832, grad_fn=<DivBackward0>)\n",
            "For 27 iteration loss is 90.18061828613281\n",
            "tensor(90.1806, grad_fn=<DivBackward0>)\n",
            "For 28 iteration loss is 89.09181213378906\n",
            "tensor(89.0918, grad_fn=<DivBackward0>)\n",
            "For 29 iteration loss is 88.01668548583984\n",
            "tensor(88.0167, grad_fn=<DivBackward0>)\n",
            "For 30 iteration loss is 86.95509338378906\n",
            "tensor(86.9551, grad_fn=<DivBackward0>)\n",
            "For 31 iteration loss is 85.90673065185547\n",
            "tensor(85.9067, grad_fn=<DivBackward0>)\n",
            "For 32 iteration loss is 84.87164306640625\n",
            "tensor(84.8716, grad_fn=<DivBackward0>)\n",
            "For 33 iteration loss is 83.84944915771484\n",
            "tensor(83.8494, grad_fn=<DivBackward0>)\n",
            "For 34 iteration loss is 82.84012603759766\n",
            "tensor(82.8401, grad_fn=<DivBackward0>)\n",
            "For 35 iteration loss is 81.84349060058594\n",
            "tensor(81.8435, grad_fn=<DivBackward0>)\n",
            "For 36 iteration loss is 80.85933685302734\n",
            "tensor(80.8593, grad_fn=<DivBackward0>)\n",
            "For 37 iteration loss is 79.88748931884766\n",
            "tensor(79.8875, grad_fn=<DivBackward0>)\n",
            "For 38 iteration loss is 78.92789459228516\n",
            "tensor(78.9279, grad_fn=<DivBackward0>)\n",
            "For 39 iteration loss is 77.98028564453125\n",
            "tensor(77.9803, grad_fn=<DivBackward0>)\n",
            "For 40 iteration loss is 77.04460144042969\n",
            "tensor(77.0446, grad_fn=<DivBackward0>)\n",
            "For 41 iteration loss is 76.12064361572266\n",
            "tensor(76.1206, grad_fn=<DivBackward0>)\n",
            "For 42 iteration loss is 75.208251953125\n",
            "tensor(75.2083, grad_fn=<DivBackward0>)\n",
            "For 43 iteration loss is 74.30732727050781\n",
            "tensor(74.3073, grad_fn=<DivBackward0>)\n",
            "For 44 iteration loss is 73.41768646240234\n",
            "tensor(73.4177, grad_fn=<DivBackward0>)\n",
            "For 45 iteration loss is 72.53922271728516\n",
            "tensor(72.5392, grad_fn=<DivBackward0>)\n",
            "For 46 iteration loss is 71.6717300415039\n",
            "tensor(71.6717, grad_fn=<DivBackward0>)\n",
            "For 47 iteration loss is 70.8151626586914\n",
            "tensor(70.8152, grad_fn=<DivBackward0>)\n",
            "For 48 iteration loss is 69.96934509277344\n",
            "tensor(69.9693, grad_fn=<DivBackward0>)\n",
            "For 49 iteration loss is 69.13404846191406\n",
            "tensor(69.1340, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finalmod = model(inputs)\n",
        "mseloss = mse(finalmod, targets)\n",
        "print(mseloss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iuYOR71yLfW",
        "outputId": "3589cb4c-b1bf-4dac-a89d-1a150680d406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(68.3093, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    }
  ]
}